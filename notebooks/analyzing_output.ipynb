{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c07a9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/yali/MEGA/Hack The Tockenizer/notebooks\n",
    "# %cd /home/dpinto/hack_the_tokenizer/notebooks\n",
    "# %cd \"C:\\Users\\yakim\\Documents\\MEGA\\03. Vida Acad√©mica\\03. Mestrado Ciencias Computadores\\Dissertacao\\Hack The Tockenizer\\notebooks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b83a764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime as dt\n",
    "from io import StringIO\n",
    "import ipywidgets\n",
    "from IPython.display import display, HTML\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "output_dir = Path(os.getcwd()).parent / \"outputs\"\n",
    "\n",
    "# Set plotly as the default plotting backend\n",
    "pd.options.plotting.backend = \"plotly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2630ec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs: dict[str|int, pd.DataFrame] = {}\n",
    "results: dict[str, dict] = {}\n",
    "for file in tqdm.tqdm(os.listdir(output_dir), desc='Loading files'):\n",
    "    if file.endswith(\"parquet\"):\n",
    "        key = dt.datetime.strptime(str(file), 'analysis_%Y%m%d%H%M%S.parquet').strftime('analysis@%Y-%m-%d %H:%M:%S')\n",
    "        dfs[key] = pd.read_parquet(output_dir / file)\n",
    "        dfs[len(dfs.keys()) // 2] = dfs[key]   # Save a copy with \"num index\" for easier access\n",
    "\n",
    "        # Convert Categorical columns back to \"number\" or \"string\"\n",
    "        for col in dfs[key].select_dtypes(include=['category']).columns:\n",
    "            # Try converting to numeric first, if that fails convert to string\n",
    "            try:\n",
    "                dfs[key][col] = dfs[key][col].astype(int)\n",
    "            except:\n",
    "                dfs[key][col] = dfs[key][col].astype(str)\n",
    "\n",
    "        # Convert unsigned integer columns to regular integers\n",
    "        for col in dfs[key].select_dtypes(include=[np.unsignedinteger]).columns:\n",
    "            dfs[key][col] = dfs[key][col].astype(int)\n",
    "    elif file.endswith(\"json\") and 'FBoost' not in file:\n",
    "        with open(output_dir / file, 'r', encoding='utf-8') as f:\n",
    "            key = dt.datetime.strptime(str(file), 'results_%Y%m%d%H%M%S.json').strftime('results@%Y-%m-%d %H:%M:%S')\n",
    "            results[key] = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40377a0d",
   "metadata": {},
   "source": [
    "# Defining Analysis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4064f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Scale menus\n",
    "log_button = lambda x, y, axis: dict(\n",
    "    type=\"buttons\",\n",
    "    x=x,\n",
    "    y=y,\n",
    "    active=0,  # Set initial state (0 for linear)\n",
    "    buttons=[\n",
    "        dict(\n",
    "            label=\"Log (X-Axis)\",\n",
    "            method=\"relayout\",\n",
    "            args=[{f\"{axis}.type\": \"linear\"}],\n",
    "            args2=[{f\"{axis}.type\": \"log\"}]\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb1629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rank_comparison(df: pd.DataFrame, *__, width=1000, **_):\n",
    "\n",
    "    new_tokens = df.groupby(by=['new_token_rank'], as_index=False)[['new_token_id']].count()\n",
    "    old_tokens = df.groupby(by=['old_token_rank'], as_index=False)[['new_token_id']].count() \n",
    "\n",
    "    new_tokens.columns = ['rank', '#new_token']\n",
    "    old_tokens.columns = ['rank', '#old_token']\n",
    "\n",
    "    df = new_tokens.merge(old_tokens, how='outer').fillna(0)\n",
    "    df = df.sort_values(by='rank', ascending=True).reset_index(drop=True)\n",
    "    df['#new_token_acc'] = df['#new_token'].cumsum()\n",
    "    df['#old_token_acc'] = df['#old_token'].cumsum()\n",
    "\n",
    "    fig = make_subplots(rows=1, cols=2, subplot_titles=['Rank Distribution', 'Rank Accumulative Distribution'])\n",
    "    # Plotting the normal view\n",
    "    fig_normal = df.plot(x='rank', y=['#new_token', '#old_token'], title='Rank Distribution')\n",
    "\n",
    "    # Plotting accumulative view\n",
    "    fig_acc = df.plot(x='rank', y=['#new_token_acc', '#old_token_acc'], title='Rank Acc Distribution')\n",
    "\n",
    "\n",
    "    # Add traces to subplot\n",
    "    for trace in fig_normal.data:\n",
    "        fig.add_trace(trace, row=1, col=1)\n",
    "    for trace in fig_acc.data:\n",
    "        fig.add_trace(trace, row=1, col=2)\n",
    "\n",
    "    # Update layout\n",
    "    button_width = 0.30\n",
    "    button_coords = (0.12, 1.15)\n",
    "    fig.update_layout(\n",
    "        title_text=\"Rank Distribution [NewTokens Vs OldTokens]\",\n",
    "        showlegend=True,\n",
    "        width=width*2.2,\n",
    "        updatemenus = [\n",
    "            log_button(button_coords[0], button_coords[1], 'xaxis'),\n",
    "            log_button(button_coords[0]+button_width*1, button_coords[1], 'yaxis'),\n",
    "            log_button(button_coords[0]+button_width*1 + 0.25, button_coords[1], 'xaxis2'),\n",
    "            log_button(button_coords[0]+button_width*2 + 0.25, button_coords[1], 'yaxis2'),\n",
    "        ] # type: ignore\n",
    "    )\n",
    "    return [fig]\n",
    "\n",
    "def get_logit_comparison(df: pd.DataFrame, *__, width=1000, **_):\n",
    "    new_tokens = df.groupby(by=['new_token_logits'], as_index=False)[['new_token_id']].count()\n",
    "    old_tokens = df.groupby(by=['old_token_logits'], as_index=False)[['new_token_id']].count() \n",
    "\n",
    "    new_tokens.columns = ['logits', '#new_token']\n",
    "    old_tokens.columns = ['logits', '#old_token']\n",
    "\n",
    "    df = new_tokens.merge(old_tokens, how='outer').fillna(0)\n",
    "    df = df.sort_values(by='logits', ascending=True).reset_index(drop=True)\n",
    "\n",
    "    # Plotting the normal view\n",
    "    fig = df.plot(x='logits', y=['#new_token', '#old_token'], title='Logits Distribution')\n",
    "\n",
    "    # Update layout\n",
    "    button_width = 0.30\n",
    "    button_coords = (0.12, 1.15)\n",
    "    fig.update_layout(\n",
    "        title_text=\"Logits Distribution [NewTokens Vs OldTokens]\",\n",
    "        showlegend=True,\n",
    "        width=width*2.2,\n",
    "        updatemenus = [\n",
    "            log_button(button_coords[0], button_coords[1], 'xaxis'),\n",
    "            log_button(button_coords[0]+button_width*1, button_coords[1], 'yaxis'),\n",
    "        ] # type: ignore\n",
    "    )\n",
    "    return [fig]\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def get_rank_diff_whiskers(df: pd.DataFrame, *__, width=1000, height=400, **_):\n",
    "    # Calculate rank differences for all models\n",
    "    df = df.copy()\n",
    "    df['rank_diff'] = df['new_token_rank'] - df['old_token_rank']\n",
    "    \n",
    "    # Get unique models and sort them for consistent ordering\n",
    "    models = sorted(df['model'].unique())\n",
    "    \n",
    "    figures = []\n",
    "    \n",
    "    # Create one vertical box plot per model\n",
    "    for model in models:\n",
    "        model_data = df[df['model'] == model]\n",
    "        \n",
    "        fig = go.Figure()\n",
    "        \n",
    "        fig.add_trace(go.Box(\n",
    "            y=model_data['rank_diff'],\n",
    "            name=model,\n",
    "            boxpoints='outliers',\n",
    "            marker_color='rgb(8,81,156)',\n",
    "            line_color='rgb(8,81,156)'\n",
    "        ))\n",
    "        \n",
    "        # Update layout for this figure\n",
    "        fig.update_layout(\n",
    "            title_text=f\"Rank Difference: {model} (New - Old Rank)\",\n",
    "            showlegend=False,\n",
    "            width=width,\n",
    "            height=height,\n",
    "            margin=dict(t=50, b=50, l=50, r=50),\n",
    "            yaxis_title=\"Rank Difference\"\n",
    "        )\n",
    "        \n",
    "        # Add horizontal reference line at y=0\n",
    "        fig.add_hline(y=0, line_dash=\"dash\", line_color=\"red\")\n",
    "        \n",
    "        figures.append(fig)\n",
    "    \n",
    "    \n",
    "    fig = make_subplots(rows=1, cols=len(figures), subplot_titles=['Rank Distribution', 'Rank Accumulative Distribution'])\n",
    "\n",
    "    # Add traces to subplot\n",
    "    for col, figure in enumerate(figures):\n",
    "        for trace in figure.data:\n",
    "            fig.add_trace(trace, row=1, col=col+1)\n",
    "    return [fig]\n",
    "\n",
    "def get_metrics_aux(result, version):\n",
    "    output = []\n",
    "    for model_type, results in result['RESULTS'].items():\n",
    "        output.append({'model': result['RUN_CONFIGS']['model_name'], 'version': version, 'model_type': model_type}) \n",
    "        for metric in results['Metrics'].keys():\n",
    "            output[-1][metric] = results['Metrics'][metric]\n",
    "        for benchmark in results['Benchmarks'].keys():\n",
    "            output[-1][benchmark] = results['Benchmarks'][benchmark]['result']\n",
    "    return pd.DataFrame(output)\n",
    "def get_metrics(result, version, *_, **__):\n",
    "    df = get_metrics_aux(result, version)\n",
    "    display(ipywidgets.HTML(df.to_html(index=False)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a17285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_analysis(df, result: dict, *args, **kwargs):\n",
    "    display(ipywidgets.HTML('<h3>Run Config</h3>\\n<ul>{}</ul><h3>Metrics</h3>'.format('\\n'.join([f'<li>{k}: {v}</li>' for k, v in result['RUN_CONFIGS'].items()]))))\n",
    "    get_metrics(result, *args, **kwargs)\n",
    "    display(ipywidgets.HTML('<h3>Comparisons (NewTokens Vs OldTokens)</h3>'))\n",
    "    figs = []\n",
    "    figs.extend(get_rank_comparison(df, *args, **kwargs))\n",
    "    figs.extend(get_logit_comparison(df, *args, **kwargs))\n",
    "    figs.extend(get_rank_diff_whiskers(df, *args, **kwargs))\n",
    "    for fig in figs: fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3376069",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "options = [str(file) for file in dfs.keys() if isinstance(file, str)]\n",
    "options.sort()\n",
    "file_selection: ipywidgets.Dropdown = ipywidgets.Dropdown(\n",
    "    options=options + ['all'],\n",
    "    value='all',\n",
    "    description='File:',\n",
    "    disabled=False,\n",
    ")\n",
    "width_slider: ipywidgets.IntSlider = ipywidgets.IntSlider(\n",
    "    value=700,\n",
    "    min=200,\n",
    "    max=1000,\n",
    "    step=1,\n",
    "    description='Width:',\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "height_slider: ipywidgets.IntSlider = ipywidgets.IntSlider(\n",
    "    value=400,\n",
    "    min=200,\n",
    "    max=1000,\n",
    "    step=1,\n",
    "    description='Height:',\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "execute_button = ipywidgets.Button(\n",
    "    description='Execute',\n",
    "    disabled=False,\n",
    "    button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Execute',\n",
    ")\n",
    "\n",
    "\n",
    "out: ipywidgets.Output = ipywidgets.Output(layout={'border': '1px solid black'})\n",
    "def on_button_clicked(_):\n",
    "    # out.clear_output()\n",
    "    items = [file_selection.value]\n",
    "    if file_selection.value == 'all':\n",
    "        items = options.copy()\n",
    "    for analysis in items:\n",
    "        df = dfs[analysis] # type: ignore\n",
    "        result = results[analysis.replace('analysis', 'results')]  # type: ignore\n",
    "        with out:\n",
    "            # Filtering timestamp\n",
    "            display(ipywidgets.HTML('<h1 style=\"text-align:center\">MODEL: {}<h1>'.format(df['model'].min().replace('[NEW_TOKENS]', ''))))\n",
    "            display(ipywidgets.HTML(f'<h3 style=\"text-align:center; margin-top: -10px\">{analysis}</h3>'))\n",
    "\n",
    "            run_analysis(df, result, analysis, width=width_slider.value, heigt=height_slider.value)\n",
    "            display(ipywidgets.HTML('<div style=\"position: relative; width:100%; margin: 20px; height:4px;border-bottom: solid black 1px;border-top: solid black 1px;\"></div√ü>'))\n",
    "\n",
    "execute_button.on_click(on_button_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39fef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all metrics for all runs\n",
    "output = []\n",
    "for version, result in results.items():\n",
    "    output.append(get_metrics_aux(result, version))\n",
    "    output[-1]['number_new_tokens'] = result['RUN_CONFIGS']['number_new_tokens']\n",
    "    # Add the \"Run Configs\" to the dataframe\n",
    "    # for key, val in result['RUN_CONFIGS'].items():\n",
    "        # output[-1][key] = val\n",
    "tmp = pd.concat(output).reset_index(drop=True).sort_values(by=['model', 'number_new_tokens', 'model_type'])\n",
    "tmp.to_csv('RESULTS_SUMMARY_{}.csv'.format(pd.Timestamp.now().strftime('%Y%m%d%H%M%S')), index=False)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1349ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3d6bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(file_selection)\n",
    "display(width_slider)\n",
    "display(execute_button)\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d171b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv('RESULTS_SUMMARY_20250727065621.csv')\n",
    "df2 = pd.read_csv('RESULTS_SUMMARY_20250813090924.csv')\n",
    "\n",
    "df = df1.merge(df2, on=['model', 'model_type', 'number_new_tokens'], how='outer')\n",
    "\n",
    "df = df[[\n",
    "    'number_new_tokens', 'model', 'model_type',\n",
    "    'version_x', 'version_y', \n",
    "    'FertilityInput_x', 'FertilityInput_y', \n",
    "    'Perplexity',\n",
    "    'FertilityOutput_x', 'FertilityOutput_y',\n",
    "    'MMLU',\n",
    "    'CalamePT_x', 'CalamePT_y',\n",
    "    'SupergluePTPT_x', 'SupergluePTPT_y'\n",
    "]]\n",
    "# Keeping only most recent data\n",
    "# df = df.drop(columns=df.columns[df.columns.str.endswith('_x')].tolist())\n",
    "for col in df.columns[df.columns.str.endswith('_y')]:\n",
    "    df[col[:-2]] = df[col].fillna(df[col[:-2] + '_x'])\n",
    "df = df.drop(columns=df.columns[df.columns.str.endswith('_x') | df.columns.str.endswith('_y')].tolist()).sort_values(by=['model', 'number_new_tokens', 'model_type'])\n",
    "# Remove baseline except when number_new_tokens == 1000\n",
    "df[(df['model_type'] != 'BASELINE') | (df['number_new_tokens'] == 1000)]\n",
    "\n",
    "# Sort columns\n",
    "df = df[[\n",
    "    'number_new_tokens', 'model', 'model_type',\n",
    "    'version',\n",
    "    'FertilityInput',\n",
    "    'Perplexity',\n",
    "    'FertilityOutput',\n",
    "    'MMLU',\n",
    "    'CalamePT',\n",
    "    'SupergluePTPT'\n",
    "]]\n",
    "df.to_csv('RESULTS_SUMMARY_{}.csv'.format(pd.Timestamp.now().strftime('%Y%m%d%H%M%S')), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8734452a",
   "metadata": {},
   "source": [
    "# MANUAL SECTION\n",
    "\n",
    "This section highlights the manual merge of different results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a9617e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv('RESULTS_SUMMARY_20250813094505.csv')\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44586219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import os\n",
    "\n",
    "dfs = []\n",
    "for file in tqdm.tqdm(os.listdir(output_dir) / 'FertilityBoost_Outputs', desc='Loading files'):\n",
    "    if not file.startswith('FBoost'): continue\n",
    "    elif file.endswith(\"json\"):\n",
    "        with open(output_dir / file, 'r', encoding='utf-8') as f:\n",
    "            key = dt.datetime.strptime(str(file), 'FBoost_results_%Y%m%d%H%M%S.json').strftime('results@%Y-%m-%d %H:%M:%S')\n",
    "            result = json.load(f)\n",
    "            config = result['RUN_CONFIGS']\n",
    "            run_configs = {\n",
    "                'number_new_tokens': config['number_new_tokens'],\n",
    "                'model': config['model_name'],\n",
    "                'version': key\n",
    "            }\n",
    "            rows = []\n",
    "            for model_type in result['RESULTS'].keys():\n",
    "                rows.append(run_configs.copy())\n",
    "                rows[-1]['model_type'] = model_type\n",
    "                for metric_name, metric_val in result['RESULTS'][model_type]['Metrics'].items():\n",
    "                    rows[-1][metric_name] = metric_val\n",
    "            dfs.append(pd.DataFrame(rows))\n",
    "\n",
    "df = pd.concat(dfs).reset_index(drop=True).sort_values(by=['model', 'number_new_tokens', 'model_type'])\n",
    "df['FertilityBoost [Mean]'] = df[df.columns[df.columns.str.startswith('FertilityBoost')]].mean(axis=1)\n",
    "df['FertilityBoost [STD]'] = df[df.columns[df.columns.str.startswith('FertilityBoost')]].std(axis=1)\n",
    "df['FertilityBoost'] = df.apply(lambda x: f'{x[\"FertilityBoost [Mean]\"]:.2%} ¬± {x[\"FertilityBoost [STD]\"]:.2%}', axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f2439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.merge(df, on=['number_new_tokens', 'model', 'model_type'], suffixes=('', '_y'), how='left').drop(columns=['version_y']).to_csv('RESULTS_SUMMARY_{}.csv'.format(pd.Timestamp.now().strftime('%Y%m%d%H%M%S')), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

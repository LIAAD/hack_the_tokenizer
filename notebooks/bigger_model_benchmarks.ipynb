{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08318759",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "\n",
    "Calculating benchmarks results for a bigger model (Qwen2.5-1.5B) before and after adding the new tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c3ba48",
   "metadata": {},
   "source": [
    "Initial imports and variable initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "affd098f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import pathlib\n",
    "import tqdm\n",
    "import os\n",
    "import re\n",
    "os.chdir('/home/yali/MEGA/Hack The Tockenizer/tests')\n",
    "sys.path.insert(1, pathlib.Path('..').resolve().as_posix())\n",
    "from src import utils, loader, hack\n",
    "from src.DatasetClass import ListDataset, TextDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "DEVICE                  = 'cuda'\n",
    "GENERATION_BATCH_SIZE   = 8\n",
    "MODEL                   = 'Qwen/Qwen2.5-1.5B-Instruct'\n",
    "TEMPERATURE             = 10e-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fd488e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7924,   11,  323,  279, 1372,  315, 4143,  304, 1817, 1874,  374,  220,\n",
       "           16,   15,   13,  576, 2790, 2783,  369,  678, 5203]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate(tokenizer.encode('ola', return_tensors='pt').to(DEVICE), top_p=None, top_k=None, temperature=None, do_sample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7f3141",
   "metadata": {},
   "source": [
    "Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab3e80b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = loader.load_model_and_tokenizer(\n",
    "    model_name=MODEL,\n",
    "    device=DEVICE,\n",
    "    model_kwargs = { 'torch_dtype': torch.bfloat16},\n",
    "    tokenizer_kwargs={'padding_side': 'left'}\n",
    ")\n",
    "original_tokenizer = loader.load_model_and_tokenizer(\n",
    "    model_name=MODEL,\n",
    "    device='cpu',\n",
    "    model_kwargs = { 'torch_dtype': torch.bfloat16},\n",
    "    tokenizer_kwargs={'padding_side': 'left'}\n",
    ")[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1985d183",
   "metadata": {},
   "source": [
    "# CalamePT Benchmark\n",
    "\n",
    "Considering **ONLY** CalamePT, currently not considering the SuperGluePTPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "479618cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.benchmark as Benchmark\n",
    "from src.benchmark.CalamePT import CalamePT\n",
    "\n",
    "# Removing \"SuperGluePTPT\" from the Benchmarks\n",
    "benchmark = Benchmark.Benchmarks([CalamePT()])\n",
    "\n",
    "# Adding the Batch Size (to generate in parallel)\n",
    "benchmark.config['parallel_batch_size'] = GENERATION_BATCH_SIZE\n",
    "benchmark.config['max_new_tokens']      = max(len(tokenizer.encode(x)) for x in CalamePT().df['last_word'].values) + 1   # Maximum tokenization of predicted words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800b2e69",
   "metadata": {},
   "source": [
    "## Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df5bb4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<Qwen/Qwen2.5-1.5B-Instruct> Calculating inferences for inputs: 100%|██████████| 260/260 [01:21<00:00,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`CalamePT` Accuracy for Baseline Model `Qwen/Qwen2.5-1.5B-Instruct` = 49.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "benchmark_results = benchmark.run(model, tokenizer, generation_kwargs={'temperature': TEMPERATURE}, store_generation_data=False)\n",
    "print(f\"`CalamePT` Accuracy for Baseline Model `{model.name_or_path}` = {benchmark_results['CalamePT']['result']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0059b1",
   "metadata": {},
   "source": [
    "## Model with additional Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84468a91",
   "metadata": {},
   "source": [
    "### Adding new tokens to model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bd9e40",
   "metadata": {},
   "source": [
    "1. Fetching the new tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d32f52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------\n",
    "#           Train Tokenizer with PT Dataset               \n",
    "# ----------------------------------------------------\n",
    "# Step 1. Train a new portuguese vocabulary\n",
    "# TODO: Find a way to fix the training... Maybe use numpy random to set a seed?\n",
    "#   TODO: Verify that the `new_tokens` list is always the same (ignoring order)\n",
    "pt_tokenizer = hack.TokenizerHack(device=DEVICE).train_tokenizer(trainer_kwargs={'vocab_size': 10000})\n",
    "\n",
    "# Step 2. Find tokens in `pt_tokenizer` not in \n",
    "new_tokens = set(pt_tokenizer.get_vocab().keys())\n",
    "new_tokens = new_tokens.difference(set(tokenizer.vocab.keys()))\n",
    "\n",
    "new_tokens = [new_token for new_token in new_tokens if not new_token contido in ANY original_tokens]\n",
    "# Removing the 'Ġ' tokens and fixing maybe some others\n",
    "new_tokens = set([tokenizer.decoder.decode([new_token]) for new_token in new_tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c35a32b",
   "metadata": {},
   "source": [
    "2. Update the model Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75b1eacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(156705, 1536)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------------------------------\n",
    "#               Update Model Vocabulary               \n",
    "# ----------------------------------------------------\n",
    "# Save the original tokenizations\n",
    "original_tokenization = {t: tokenizer.encode(t) for t in new_tokens}    # Necessary for the training bellow\n",
    "tokenizer.add_tokens(list(new_tokens))\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f92817b",
   "metadata": {},
   "source": [
    "3. Initialize the embeddings using the Weighted average $w_i = w_{i+1} \\times K$ with $K=5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b365d489",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing the embeddings for the new_tokens: 100%|██████████| 5040/5040 [00:00<00:00, 8263.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# Step 4. Calculate the new embeddings for the new tokens\n",
    "embed = model.get_input_embeddings().weight.clone().to('cpu')\n",
    "new_embed = model.get_input_embeddings()\n",
    "\n",
    "# Initialize the embedding using the weighted average model\n",
    "K = 1.5 # Tested for values [1, 2, 3, 4, 5, 0.9, 0.8, 1.1, 1.2, ..., 1.6] and the best was 1.5 with (3.13%)\n",
    "with torch.no_grad():\n",
    "    for new_token in tqdm.tqdm(new_tokens, desc='Initializing the embeddings for the new_tokens'):\n",
    "        new_token_id = tokenizer.encode(new_token)[0]\n",
    "        # Find the old embedding for the token\n",
    "        tokenization = original_tokenization[new_token]\n",
    "        token_embed = torch.stack([embed[t_id] for t_id in tokenization]).to(DEVICE)\n",
    "        # Calculating the embedding weights\n",
    "        embedding_weights = torch.asarray([K**i if K**i < 2**64 else 0 for i in range(token_embed.shape[0], 0, -1)]).to(DEVICE)\n",
    "        # embedding_weights = torch.asarray([K**i for i in range(token_embed.shape[0], 0, -1)]).to(DEVICE)\n",
    "        embedding_weights = embedding_weights / embedding_weights.sum()\n",
    "\n",
    "        # Create a new token embed using the weighted average of the embeddings\n",
    "        new_token_embed = torch.sum(token_embed * embedding_weights[:, None], dim=0)\n",
    "        # new_token_embed = token_embed[0]\n",
    "        # Update embedding of the new_token in the hacked_model\n",
    "        _ = new_embed.weight[new_token_id].data.copy_(new_token_embed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cc889e",
   "metadata": {},
   "source": [
    "### Benchmark Computation\n",
    "\n",
    "Calculating the results with the added tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77f11654",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<Qwen/Qwen2.5-1.5B-Instruct-ADDED_TOKENS_INIT_K=1.5> Calculating inferences for inputs: 100%|██████████| 260/260 [01:34<00:00,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`CalamePT` Accuracy for Baseline  Model `Qwen/Qwen2.5-1.5B-Instruct-ADDED_TOKENS_INIT_K=1.5` = 49.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Update model name\n",
    "model.name_or_path = f'{MODEL}-ADDED_TOKENS_INIT_K={K}'\n",
    "\n",
    "# Update the \"max_new_tokens\" (since we added new_tokens, we may have a different value than previously)\n",
    "benchmark.config['max_new_tokens'] = max(len(tokenizer.encode(x)) for x in CalamePT().df['last_word'].values) + 1   # Maximum tokenization of predicted words\n",
    "benchmark_results_new_tokens = benchmark.run(model, tokenizer, original_tokenizer, generation_kwargs={'temperature': TEMPERATURE}, store_generation_data=False)\n",
    "print(f\"`CalamePT` Accuracy for Baseline  Model `{model.name_or_path}` = {benchmark_results_new_tokens['CalamePT']['result']:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7857619",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation with new tokenizer = ` Ela correu durante horas para alcançar a linha de meta, se leves deu quebrar la`\n",
      "Generation with \"old tokenizer\" = ` Ela correu durante horas para alcançar a linha de chegada, que estava situada em 2`\n"
     ]
    }
   ],
   "source": [
    "phrase = ' Ela correu durante horas para alcançar a linha de'\n",
    "max_new_tokens = 10\n",
    "generation = tokenizer.decode(utils.generate(\n",
    "    model, tokenizer,\n",
    "    phrase,\n",
    "    DEVICE, \n",
    "    False, False,\n",
    "    max_new_tokens=max_new_tokens\n",
    ")[0])\n",
    "print(f'Generation with new tokenizer = `{generation}`')\n",
    "\n",
    "\n",
    "input_ids = tokenizer.encode(phrase)\n",
    "input_ids = [token for x in input_ids for token in original_tokenization.get(tokenizer.convert_ids_to_tokens(x), [x])]\n",
    "\n",
    "for n in range(10):\n",
    "    generation = model.generate(torch.Tensor([input_ids]).long().to(DEVICE), max_new_tokens=1)\n",
    "    generated_id = generation[0, -1].item()\n",
    "    input_ids.extend(\n",
    "        [token for token in original_tokenization.get(tokenizer.convert_ids_to_tokens(generated_id), [generated_id])]\n",
    "    )\n",
    "print(f'Generation with \"old tokenizer\" = `{tokenizer.decode(input_ids)}`')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46a8dd2",
   "metadata": {},
   "source": [
    "## Model with additional Tokens + \"Training\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67017999",
   "metadata": {},
   "source": [
    "Training the model (already has the added tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac64f97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating the embeddings for the new tokens: 100%|██████████| 5040/5040 [44:23<00:00,  1.89it/s]  \n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------\n",
    "#     Update weights of Embeddings of new_tokens      \n",
    "# ----------------------------------------------------\n",
    "# Step 4.2 Using the training phrases to update the embedding weights\n",
    "learning_rate = 1e-6\n",
    "training_phrases: list[str] = CalamePT().prediction_prompts.to_list() # CalamePT dataset \n",
    "for new_token in tqdm.tqdm(new_tokens, desc='Updating the embeddings for the new tokens'):\n",
    "    new_token_id = tokenizer.convert_tokens_to_ids(new_token)\n",
    "    new_token = tokenizer.decode(new_token_id)\n",
    "    phrases_to_generate_new_token = [p for phrase in training_phrases for p in phrase.split(new_token)[:-1] if new_token in phrase and len(p) > 0]\n",
    "\n",
    "    if len(phrases_to_generate_new_token) == 0: continue\n",
    "    # Creating the Batched dataset (to run generation for multiple phrases at the same time)\n",
    "    dataloader = DataLoader(\n",
    "        TextDataset(phrases_to_generate_new_token, tokenizer, max_length=max(len(tokenizer.tokenize(x)) for x in phrases_to_generate_new_token)),\n",
    "        batch_size=GENERATION_BATCH_SIZE,\n",
    "        shuffle=False\n",
    "    )\n",
    "    # Process the batches\n",
    "    for batch in tqdm.tqdm(dataloader,  desc=f'  Generating tokens for new_token=`{new_token}` ', leave=False):\n",
    "        # Move batch tensors to the correct device\n",
    "        input_ids = batch['input_ids'].squeeze(1).to(DEVICE)\n",
    "        attention_mask = batch['attention_mask'].squeeze(1).to(DEVICE)\n",
    "\n",
    "        # Generate text\n",
    "        outputs = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=1,\n",
    "            num_beams=1,\n",
    "            num_return_sequences=1,\n",
    "            return_dict_in_generate=True,\n",
    "            output_logits=True,\n",
    "            output_scores=True,\n",
    "            output_hidden_states=True,\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "\n",
    "        # Extract the generated sequences and their scores\n",
    "        generated_sequences = outputs.sequences\n",
    "        predicted_logits = outputs.logits\n",
    "\n",
    "        # Decode the input and generated sequences\n",
    "        input_texts = tokenizer.batch_decode(input_ids, skip_special_tokens=True)\n",
    "        generated_texts = tokenizer.batch_decode(generated_sequences, skip_special_tokens=True)\n",
    "        with torch.no_grad():\n",
    "            for i in range(len(input_texts)):\n",
    "                logits = predicted_logits[0][i]\n",
    "                logit_gradient = logits.max() - logits[new_token_id]\n",
    "                embed_out = outputs.hidden_states[0][-1][i][-1]\n",
    "                # normalize embed_out\n",
    "                embed_out = embed_out / embed_out.norm()\n",
    "\n",
    "                embed_in = new_embed.weight[new_token_id]\n",
    "\n",
    "                # Update the embedding table\n",
    "                _ = new_embed.weight[new_token_id].data.copy_((embed_in + logit_gradient * embed_out * learning_rate).to(DEVICE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecc32e0",
   "metadata": {},
   "source": [
    "### Update model name\n",
    "\n",
    "Changing the model name to include the \"added_tokens\" to distinguish between the older model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "409a35f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.name_or_path = f'{model.name_or_path} [TRAINED]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df0d075",
   "metadata": {},
   "source": [
    "### Run the benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6cc5799",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<Qwen/Qwen2.5-1.5B-Instruct-ADDED_TOKENS_INIT_K=1.5 [TRAINED]> Calculating inferences for inputs: 100%|██████████| 260/260 [01:47<00:00,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`CalamePT` Accuracy for Baseline Model `Qwen/Qwen2.5-1.5B-Instruct-ADDED_TOKENS_INIT_K=1.5 [TRAINED]` = 49.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "benchmark_results_new_tokens_trained = benchmark.run(model, tokenizer, original_tokenizer,  generation_kwargs={'temperature': TEMPERATURE})\n",
    "print(f\"`CalamePT` Accuracy for Baseline Model `{model.name_or_path}` = {benchmark_results_new_tokens_trained['CalamePT']['result']:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fd79133",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2076it [00:00, 2095.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# Finding out which \"new_tokens\" were generated\n",
    "tmp = [x['generated_ids'].max().item() for x in benchmark_results_new_tokens_trained['CalamePT']['results'][0]['benchmark_predictions']]\n",
    "# len([t for t in tmp if t>len(original_tokenizer)])\n",
    "\n",
    "# Adding flag of \"new_token_generated\" in benchmark results\n",
    "original_tokenizer_size = len(original_tokenizer)\n",
    "for i, test in tqdm.tqdm(enumerate(benchmark_results_new_tokens_trained['CalamePT']['results'][0]['benchmark_predictions'])):\n",
    "    test['has_new_token'] = len([t for t in test['generated_ids'] if t>original_tokenizer_size]) > 0\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca0c4060",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_w_new_tokens = [a.copy() for a in benchmark_results_new_tokens_trained['CalamePT']['results'][0]['benchmark_predictions'] if a['has_new_token']]\n",
    "def word_has_new_token(word: str, token_ids, new_token_start_id: int):\n",
    "    i = 1\n",
    "    cur_tokens = [token_ids[0]]\n",
    "    while tokenizer.decode(cur_tokens).strip().lower() != word.lower() and i<len(token_ids):\n",
    "        cur_tokens.append(token_ids[i])\n",
    "        i+=1\n",
    "    return len([t for t in cur_tokens if new_token_start_id < t]) > 0\n",
    "\n",
    "new_token_start_id = len(original_tokenizer)\n",
    "for i, r in enumerate(results_w_new_tokens):\n",
    "    # Find out if \"predicted_word\" is made up of any \"new_token\"\n",
    "    results_w_new_tokens[i]['new_token_in_word'] = word_has_new_token(r['prediction'], r['generated_ids'][-8:], new_token_start_id)\n",
    "    results_w_new_tokens[i]['correct_prediction'] = r['prediction'].strip().lower() == r['correct_word'].strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a4b329dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' realidade'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([153052])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58904438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' realidade'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([153665])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "02ac5d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[155661, 3955]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\" público\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b86d892a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sentence",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "last_word",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "62ae3949-b78b-4425-acdb-40693b0fc0a5",
       "rows": [
        [
         "0",
         "0",
         " Ela correu durante horas para alcançar a linha de",
         "chegada"
        ],
        [
         "3",
         "3",
         "O Jorge trabalhava numa padaria. Todos os dias ele vendia",
         "pão"
        ],
        [
         "4",
         "4",
         "As equipas de futebol têm vários jogadores, e todos têm que respeitar o seu",
         "treinador"
        ],
        [
         "5",
         "5",
         "Os pássaros voaram alto no",
         "céu"
        ],
        [
         "7",
         "7",
         "A chuva caiu suavemente sobre as folhas das",
         "árvores"
        ],
        [
         "10",
         "10",
         "A montanha era tão alta que parecia tocar o",
         "céu"
        ],
        [
         "11",
         "11",
         "O jardim estava repleto de flores coloridas. Os pássaros cantavam alegremente nas árvores. O sol brilhava intensamente no céu",
         "azul"
        ],
        [
         "13",
         "13",
         "O mar estava agitado e as ondas arrebentavam com força na praia. As crianças construíam castelos de areia. Os surfistas aproveitavam as ",
         "ondas"
        ],
        [
         "19",
         "19",
         "A chuva caiu suavemente durante a noite. As gotas batiam na janela. O som relaxante embalou o sono",
         "profundo"
        ],
        [
         "25",
         "25",
         "Devido aos ventos fortes e ao calor abrasador, os bombeiros tiveram muita dificuldade em combater o",
         "fogo"
        ],
        [
         "30",
         "30",
         "A festa de aniversário tinha decorações temáticas incríveis. Os convidados participaram em jogos divertidos. No fim, todos comeram o",
         "bolo"
        ],
        [
         "34",
         "34",
         "A reunião de negócios foi produtiva e eficiente. As ideias foram discutidas de maneira construtiva. O acordo foi alcançado no final da",
         "reunião"
        ],
        [
         "36",
         "36",
         "O concerto ao ar livre atraiu uma multidão entusiasmada. As bandas locais mostraram seu talento musical. A música ecoou sob as ",
         "estrelas"
        ],
        [
         "39",
         "39",
         "A estação espacial anda em órbita do nosso",
         "planeta"
        ],
        [
         "41",
         "41",
         "O jogo de futebol foi emocionante do início ao fim. Os torcedores vibraram nas arquibancadas. O gol no último minuto selou a vitória da",
         "equipa"
        ],
        [
         "48",
         "48",
         "O passeio de barco pelo rio revelou paisagens pitorescas. A água calma refletia as montanhas à distância. A tranquilidade da natureza envolveu todos os que estavam a",
         "bordo"
        ],
        [
         "50",
         "50",
         "A viagem de comboio atravessou belas paisagens pelo seu caminho. Os passageiros tiraram fotos das montanhas e rios. O comboio parou em várias estações ao longo do",
         "caminho"
        ],
        [
         "53",
         "53",
         "A reserva natural abrigava uma variedade de animais selvagens. Os observadores de pássaros admiraram a diversidade de espécies. Os corvos e coelhos eram avistados com ",
         "frequência"
        ],
        [
         "54",
         "54",
         "O vento forte trouxe nuvens escuras e relâmpagos, anunciando uma",
         "tempestade"
        ],
        [
         "58",
         "58",
         "O atleta treinou arduamente e bateu o recorde mundial no salto em altura, alcançando uma",
         "vitória"
        ],
        [
         "65",
         "65",
         "A tempestade destruiu várias árvores, deixando assim um rastro de devastação na",
         "floresta"
        ],
        [
         "73",
         "73",
         "A inteligência artificial está a revolucionar a medicina, ajudando no diagnóstico de",
         "doenças"
        ],
        [
         "75",
         "75",
         "A biblioteca da universidade era um refúgio tranquilo para estudantes esfomeados por",
         "conhecimento"
        ],
        [
         "78",
         "78",
         "Acampar no deserto proporcionou uma experiência única de estar em contato com a",
         "natureza"
        ],
        [
         "81",
         "81",
         "O agricultor plantou árvores frutíferas em seu pomar. As maçãs e peras amadureciam nas árvores. As abelhas polinizavam as ",
         "flores"
        ],
        [
         "82",
         "82",
         "O projeto de reflorestamento visava restaurar áreas degradadas. As árvores nativas foram plantadas com carinho. A vegetação começou a",
         "recuperar"
        ],
        [
         "86",
         "86",
         "O lançamento do novo smartphone gerou grande expectativa. Os consumidores aguardaram ansiosamente as características e inovações. O dispositivo rapidamente se tornou um sucesso de",
         "vendas"
        ],
        [
         "92",
         "92",
         "A inovação tecnológica no setor automóvel tem se concentrado em sistemas avançados de assistência ao",
         "condutor"
        ],
        [
         "93",
         "93",
         "A engenharia automóvel está constantemente a melhorar a eficiência dos motores por meio da otimização de sistemas de injeção de",
         "combustível"
        ],
        [
         "95",
         "95",
         "Os avanços em materiais leves, como ligas de alumínio e fibra de carbono, têm desempenhado um papel crucial na construção de",
         "automóveis"
        ],
        [
         "97",
         "97",
         "O concerto de rock atraiu uma multidão de fãs enérgicos. A banda tocou seus maiores sucessos com paixão. Os espectadores cantaram junto e dançaram toda a",
         "noite"
        ],
        [
         "104",
         "104",
         "No jardim tranquilo, as flores desabrochavam em cores vibrantes. As borboletas dançavam graciosamente de flor em flor, num ",
         "espetáculo"
        ],
        [
         "113",
         "113",
         "Amigos reuniam-se ao redor das mesas, compartilhando piadas e histórias enquanto desfrutavam de bebidas ",
         "alcoólicas"
        ],
        [
         "119",
         "119",
         "As competições off-road desafiam a habilidade dos pilotos e a resistência dos seus",
         "veículos"
        ],
        [
         "120",
         "120",
         "No observatório astronômico, telescópios apontavam para o",
         "céu"
        ],
        [
         "122",
         "122",
         "A navegação marítima oferece uma perspectiva única de paisagens naturais e cidades históricas, permitindo que os viajantes explorem o",
         "oceano"
        ],
        [
         "126",
         "126",
         "O treinador implementou uma tática defensivamente sólida, mantendo assim a equipa adversária sobre",
         "controlo"
        ],
        [
         "128",
         "128",
         "O papel é uma invenção revolucionária que desempenhou um papel fundamental na difusão do",
         "conhecimento"
        ],
        [
         "131",
         "131",
         "A nanotecnologia está a revolucionar a medicina, permitindo tratamentos mais precisos e a escolha personalizada de",
         "medicamentos"
        ],
        [
         "132",
         "132",
         "A automatização industrial está a otimizar a produção em fábricas, aumentando a eficiência e reduzindo os",
         "custos"
        ],
        [
         "142",
         "142",
         "A escola de dança ofereceu aulas de salsa para iniciantes. Os alunos aprenderam os movimentos sensuais e ritmos envolventes. A salsa trouxe calor e paixão à pista de ",
         "dança"
        ],
        [
         "145",
         "145",
         "O estudo da termodinâmica é essencial para a compreensão de fenómenos naturais, como a expansão e contração de",
         "materiais"
        ],
        [
         "147",
         "147",
         "A meditação é uma prática poderosa que permite que as pessoas encontrem o seu equilíbrio",
         "emocional"
        ],
        [
         "149",
         "149",
         "O jogo estava muito renhido com a equipa da casa em vantagem. Tudo mudou quando a equipa visitante marcou o golo do",
         "empate"
        ],
        [
         "151",
         "151",
         "O chef preparou um prato delicioso. Os clientes elogiaram o seu",
         "sabor"
        ],
        [
         "154",
         "154",
         "Antes do início do concerto, os músicos estavam a preparar os seus próprios",
         "instrumentos"
        ],
        [
         "156",
         "156",
         "Os estudantes de Farmácia têm que aprender muito sobre o corpo humano e sobre química. Isto dá-lhes competências para poderem desenvolver novos",
         "medicamentos"
        ],
        [
         "157",
         "157",
         "Na loja de brinquedos, as crianças chateavam os pais para comprarem brinquedos",
         "novos"
        ],
        [
         "163",
         "163",
         "Os músicos trabalham juntos para criar novas músicas dentro do",
         "estúdio"
        ],
        [
         "164",
         "164",
         "No centro de reabilitação animal, veterinários cuidam de animais que precisam de",
         "ajuda"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 647
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>last_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ela correu durante horas para alcançar a linh...</td>\n",
       "      <td>chegada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>O Jorge trabalhava numa padaria. Todos os dias...</td>\n",
       "      <td>pão</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>As equipas de futebol têm vários jogadores, e ...</td>\n",
       "      <td>treinador</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Os pássaros voaram alto no</td>\n",
       "      <td>céu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>A chuva caiu suavemente sobre as folhas das</td>\n",
       "      <td>árvores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>1661</td>\n",
       "      <td>Uma nova proposta para acabar com o roaming fo...</td>\n",
       "      <td>proposta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>1665</td>\n",
       "      <td>A requalificação dos espaços verdes é uma prio...</td>\n",
       "      <td>verdes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>1666</td>\n",
       "      <td>Os adeptos de hóquei em patins podem esperar u...</td>\n",
       "      <td>equipas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>1667</td>\n",
       "      <td>Uma estrela brilhante se junta às demais no fa...</td>\n",
       "      <td>atriz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>1669</td>\n",
       "      <td>No contexto apresentado, várias organizações d...</td>\n",
       "      <td>trabalhadores</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>647 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                           sentence      last_word\n",
       "0        0   Ela correu durante horas para alcançar a linh...        chegada\n",
       "3        3  O Jorge trabalhava numa padaria. Todos os dias...            pão\n",
       "4        4  As equipas de futebol têm vários jogadores, e ...      treinador\n",
       "5        5                         Os pássaros voaram alto no            céu\n",
       "7        7        A chuva caiu suavemente sobre as folhas das        árvores\n",
       "...    ...                                                ...            ...\n",
       "1661  1661  Uma nova proposta para acabar com o roaming fo...       proposta\n",
       "1665  1665  A requalificação dos espaços verdes é uma prio...         verdes\n",
       "1666  1666  Os adeptos de hóquei em patins podem esperar u...        equipas\n",
       "1667  1667  Uma estrela brilhante se junta às demais no fa...          atriz\n",
       "1669  1669  No contexto apresentado, várias organizações d...  trabalhadores\n",
       "\n",
       "[647 rows x 3 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark.benchmarks[0].df[(' '+benchmark.benchmarks[0].df['last_word']).apply(lambda x: tokenizer.encode(x)[0] >= 151665 and len(tokenizer.tokenize(x)) == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78763c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Num mundo onde a democracia é sacrificada em prol dos lucros dos mercados, negando-nos direitos e liberdades, surge a necessidade de despertar para a realidade. O projeto europeu falhou ao submeter-se ao poder financeiro, abandonando os direitos sociais e económicos dos povos. A pobreza e o desemprego crescem como consequência deste erro. Não devemos esperar pela derrota, mas sim enfrentar as imposições europeias de frente. A alternativa aos projetos reacionários não é a moderação, mas sim a coragem de questionar um sistema que pretere as gerações futuras. A xenofobia cresce e alimenta-se da austeridade imposta aos povos. Agradeçamos aos que lutaram pela liberdade e recordemos que o sonho de um futuro melhor continua a ser possível, mesmo perante a dura',\n",
       "  'prediction': 'realidade',\n",
       "  'correct_word': 'realidade',\n",
       "  'generated_ids': tensor([  4651,  28352,  49003,    264,  12074,  27041,   3958,  30861,   2584,\n",
       "             976,  28420,   8750,  25927,   3630,   8750,  16481,   5553,     11,\n",
       "            4184,   4883,   5279,    436,  13207,  25593,    384,   3051,  14348,\n",
       "            3452,     11,  21781,    264,   4441,   9075,    409,  38960,    529,\n",
       "             277,   3348,    264,   1931,   9075,     13,    506,  68859,  37534,\n",
       "              84,  25484,  18166,  14845,   1186,  59422,   7806,  14845,  28538,\n",
       "           17017,   8698,     11,  15313,   4883,   2643,  13207,  25593,  12019,\n",
       "           56467,    384,  72541,  16627,   8750,  55214,    436,     13,    362,\n",
       "             281,  37608,   4360,    384,    297,    939,   3262,  67717,  45758,\n",
       "           53821,   7953,  12494,  23696,  76136,  36310,     13,  57649,   3483,\n",
       "           14946,  30057,    277,  32723,   2694,    299,   2565,     11,   9243,\n",
       "            1643,  88499,    277,    438,    732,    966,     72,  15249,  37534,\n",
       "            3473,    409,  56722,     13,    362,   6919,  27852,  42814,  45394,\n",
       "             436,    312,   5806,  37085,  12393,   3958,    264,   1463,  74744,\n",
       "              11,   9243,   1643,    264,   1829,  14661,    409,   3405,    277,\n",
       "            4443,  28828,   1709,    855,  54604,    438,    342,   2416,  15249,\n",
       "           17645,  19319,     13,    362,  52165,   1055,  40063,  45758,    346,\n",
       "             384,  37350,     64,   7806,   2994,    264,   4993,   9075,    732,\n",
       "           38531,  42814,  55214,    436,     13,    362,   6937,   3131,  10585,\n",
       "           42814,   1709,  62822,    637,  32723,   3051,  14348,   1021,    384,\n",
       "            3255,  14946,   1709,    297,   4438,   6161,    409,   4443,  64644,\n",
       "           45682,  90984,    264,   1420,  63181,     11,  40249,    817,   4942,\n",
       "             264,    294,   5690, 153665,    653,  53172,    624,     32,  38500,\n",
       "            1562,  10608]),\n",
       "  'generated_logits': [tensor([5.0625, 5.1875, 2.2344,  ..., 3.8750, 2.3281, 3.2031]),\n",
       "   tensor([15.0000,  9.8750,  4.2812,  ...,  6.1562,  7.1562,  4.7188]),\n",
       "   tensor([4.9375, 4.0312, 1.5469,  ..., 5.7188, 1.8047, 2.5312]),\n",
       "   tensor([17.3750, 11.9375,  8.8750,  ...,  5.4375,  4.8438,  2.7969]),\n",
       "   tensor([ 8.4375, 15.5625, 13.5000,  ...,  3.5625,  9.2500,  7.4688]),\n",
       "   tensor([4.6875, 6.2500, 4.6250,  ..., 5.4688, 4.2812, 7.0938]),\n",
       "   tensor([10.8750,  8.7500,  4.7500,  ...,  4.4688,  4.6250,  2.2188]),\n",
       "   tensor([8.6250, 8.7500, 2.1562,  ..., 5.4688, 6.8750, 7.3438])],\n",
       "  'has_new_token': True,\n",
       "  'new_token_in_word': True,\n",
       "  'correct_prediction': True}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[r for r in results_w_new_tokens if r['new_token_in_word'] and r['correct_prediction']]\n",
    "# results_w_new_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d79d58",
   "metadata": {},
   "source": [
    "SAVE ALL Benchmarks in a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f4e1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/home/yali/MEGA/Hack The Tockenizer/tests/qwen2.5-benchmark-results_V2_run2.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(benchmark.get_results(), f, indent=2, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a18d80",
   "metadata": {},
   "source": [
    "# Analysing the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb8a880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "with open('/home/yali/MEGA/Hack The Tockenizer/tests/qwen2.5-benchmark-results_V2_run2.json', 'r') as f:\n",
    "    results: dict[str, dict[str, dict]] = json.load(f)\n",
    "\n",
    "data = []\n",
    "for model_name in results.keys():\n",
    "    for benchmark_name in results[model_name].keys():\n",
    "        for epoch_n, result in enumerate(results[model_name][benchmark_name]['results']):\n",
    "            result: dict\n",
    "            data.append(result.copy())\n",
    "            data[-1]['model_name'] = model_name\n",
    "            data[-1]['epoch_number'] = epoch_n\n",
    "\n",
    "            r = data[-1].pop('benchmark_predictions')\n",
    "            data[-1]['original_text']   = [gen[\"text\"]          for gen in r]\n",
    "            data[-1]['expected_word']   = [gen[\"correct_word\"]  for gen in r]\n",
    "            data[-1]['predicted_word']  = [gen[\"prediction\"]    for gen in r]\n",
    "\n",
    "df = pd.DataFrame(data).explode(['original_text', 'expected_word', 'predicted_word'])\n",
    "# Changing the model name to only 2 letters, the first specifies if the model has been initialized or not, and the second one specifies if it has been trained or not\n",
    "df['model_name'] = df['model_name'].map({\n",
    "    'Qwen/Qwen2.5-1.5B-Instruct':                                   'BB',   # Baseline,    Baseline  \n",
    "    'Qwen/Qwen2.5-1.5B-Instruct [TRAINED]':                         'BT',   # Baseline,    Trained  (currently not existing)\n",
    "    'Qwen/Qwen2.5-1.5B-Instruct-ADDED_TOKENS_INIT_K=1.5':           'IB',   # Initialized, Baseline\n",
    "    'Qwen/Qwen2.5-1.5B-Instruct-ADDED_TOKENS_INIT_K=1.5 [TRAINED]': 'IT',   # Initialized, Trained\n",
    "})\n",
    "\n",
    "\n",
    "df = df.pivot(\n",
    "    index='original_text', columns=['model_name'], values=['predicted_word', 'expected_word']\n",
    ")\n",
    "df.columns = ['_'.join(col) for col in df.columns]\n",
    "df = df[['predicted_word_BB', 'predicted_word_IB', 'predicted_word_IT', 'expected_word_BB']].reset_index().rename(columns={'expected_word_BB': 'expected_word'})\n",
    "\n",
    "for model in [f'{init}{train}' for init in ['B', 'I'] for train in ['B', 'T']]:\n",
    "    # There is no \"BaselineTrained\" model, YET\n",
    "    if model == 'BT':\n",
    "        continue\n",
    "    df[f'correct_prediction_{model}'] = df[f'predicted_word_{model}'] == df['expected_word']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f0bb2e",
   "metadata": {},
   "source": [
    "Saving to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53df0fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/home/yali/MEGA/Hack The Tockenizer/tests/qwen2.5-benchmark-results_V2_analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19e1069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next STEP: TRAIN the baseline model with a \"normal\" approach for the same amount of time and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a15626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next STEP: Remover os tokens que sao \"contidos\" em algum dos tokens no tokenizador original + Usar \"palavras\" do corpus como \"new_tokens\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08318759",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "\n",
    "Calculating benchmarks results for a bigger model (Qwen2.5-1.5B) before and after adding the new tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c3ba48",
   "metadata": {},
   "source": [
    "Initial imports and variable initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "affd098f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import pathlib\n",
    "import tqdm\n",
    "import os\n",
    "import re\n",
    "os.chdir('/home/yali/MEGA/Hack The Tockenizer/tests')\n",
    "sys.path.insert(1, pathlib.Path('..').resolve().as_posix())\n",
    "from src import utils, loader, hack\n",
    "from src.DatasetClass import ListDataset, TextDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "DEVICE                  = 'cuda'\n",
    "GENERATION_BATCH_SIZE   = 8\n",
    "MODEL                   = 'Qwen/Qwen2.5-1.5B-Instruct'\n",
    "MODEL_GEN_KWARGS = dict(top_p=None, top_k=None, temperature=None, do_sample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7f3141",
   "metadata": {},
   "source": [
    "Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab3e80b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = loader.load_model_and_tokenizer(\n",
    "    model_name=MODEL,\n",
    "    device=DEVICE,\n",
    "    model_kwargs = { 'torch_dtype': torch.bfloat16},\n",
    "    tokenizer_kwargs={'padding_side': 'left'}\n",
    ")\n",
    "original_tokenizer = loader.load_model_and_tokenizer(\n",
    "    model_name=MODEL,\n",
    "    device='cpu',\n",
    "    model_kwargs = { 'torch_dtype': torch.bfloat16},\n",
    "    tokenizer_kwargs={'padding_side': 'left'}\n",
    ")[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1985d183",
   "metadata": {},
   "source": [
    "# CalamePT Benchmark\n",
    "\n",
    "Considering **ONLY** CalamePT, currently not considering the SuperGluePTPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "479618cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.benchmark as Benchmark\n",
    "from src.benchmark.CalamePT import CalamePT\n",
    "\n",
    "# Removing \"SuperGluePTPT\" from the Benchmarks\n",
    "benchmark = Benchmark.Benchmarks([CalamePT()])\n",
    "\n",
    "# Adding the Batch Size (to generate in parallel)\n",
    "benchmark.config['parallel_batch_size'] = GENERATION_BATCH_SIZE\n",
    "benchmark.config['max_new_tokens']      = max(len(tokenizer.encode(x)) for x in CalamePT().df['last_word'].values) + 1   # Maximum tokenization of predicted words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800b2e69",
   "metadata": {},
   "source": [
    "## Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df5bb4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<Qwen/Qwen2.5-1.5B-Instruct> Calculating inferences for inputs: 100%|██████████| 260/260 [01:28<00:00,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`CalamePT` Accuracy for Baseline Model `Qwen/Qwen2.5-1.5B-Instruct` = 49.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "benchmark_results = benchmark.run(model, tokenizer, generation_kwargs=MODEL_GEN_KWARGS, store_generation_data=False)\n",
    "print(f\"`CalamePT` Accuracy for Baseline Model `{model.name_or_path}` = {benchmark_results['CalamePT']['result']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0059b1",
   "metadata": {},
   "source": [
    "## Model with additional Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84468a91",
   "metadata": {},
   "source": [
    "### Adding new tokens to model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bd9e40",
   "metadata": {},
   "source": [
    "1. Fetching the new tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d32f52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5040/5040 [00:54<00:00, 92.01it/s] \n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------\n",
    "#           Train Tokenizer with PT Dataset               \n",
    "# ----------------------------------------------------\n",
    "# Step 1. Train a new portuguese vocabulary\n",
    "# TODO: Find a way to fix the training... Maybe use numpy random to set a seed?\n",
    "#   TODO: Verify that the `new_tokens` list is always the same (ignoring order)\n",
    "pt_tokenizer = hack.TokenizerHack(device=DEVICE).train_tokenizer(trainer_kwargs={'vocab_size': 10000})\n",
    "\n",
    "# Step 2. Find tokens in `pt_tokenizer` not in \n",
    "new_tokens = set(pt_tokenizer.get_vocab().keys())\n",
    "new_tokens = new_tokens.difference(set(tokenizer.vocab.keys()))\n",
    "\n",
    "# Removing the 'Ġ' tokens and fixing maybe some others\n",
    "new_tokens = set([tokenizer.decoder.decode([new_token]) for new_token in new_tokens])\n",
    "\n",
    "# Remove the tokens which may be \"contained\" in any of the original tokens (for instance, \"publ\" is contained in \"publico\" so \"publ\" will be removed)\n",
    "__new_tokens = []\n",
    "tokenizer_vocab_keys = list(tokenizer.decode(x) for x in range(len(tokenizer)))\n",
    "for new_token in tqdm.tqdm(new_tokens, total=len(new_tokens)):\n",
    "    add_new_token = True\n",
    "    for token in tokenizer_vocab_keys:\n",
    "        if token.startswith(new_token):\n",
    "            add_new_token = False\n",
    "            break\n",
    "    if add_new_token: __new_tokens.append(new_token)\n",
    "new_tokens = set(__new_tokens)\n",
    "\n",
    "######### BELLOW SECTION IS THE LAST LOOP BUT RUNNING IN PARALLEL USING joblib\n",
    "# import joblib as jb\n",
    "# import tqdm\n",
    "\n",
    "# def should_add_token(new_token, vocab_keys):\n",
    "#     for token in vocab_keys:\n",
    "#         if token.startswith(new_token):\n",
    "#             return False\n",
    "#     return True\n",
    "\n",
    "# def filter_new_tokens(new_tokens, tokenizer_vocab_keys):\n",
    "#     vocab_keys = list(tokenizer_vocab_keys)  # Avoid repeated conversions in workers\n",
    "    \n",
    "#     # Parallel processing with generator output\n",
    "#     results = jb.Parallel(n_jobs=7, backend=\"loky\", return_as=\"generator\")(\n",
    "#         jb.delayed(should_add_token)(new_token, vocab_keys)\n",
    "#         for new_token in new_tokens\n",
    "#     )\n",
    "    \n",
    "#     # Wrap results in tqdm for progress tracking\n",
    "#     for new_token, should_add in tqdm.tqdm(\n",
    "#         zip(new_tokens, results),\n",
    "#         total=len(new_tokens),\n",
    "#         desc=\"Filtering tokens\"\n",
    "#     ):\n",
    "#         if should_add:\n",
    "#             yield new_token\n",
    "\n",
    "# # Usage:\n",
    "# tokenizer_vocab_keys = list(tokenizer.decode(x) for x in range(len(tokenizer)))\n",
    "# new_tokens_filtered_gen = filter_new_tokens(new_tokens, tokenizer_vocab_keys)\n",
    "# new_tokens = set(new_tokens_filtered_gen)  # Consume the generator and convert to set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c35a32b",
   "metadata": {},
   "source": [
    "2. Update the model Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75b1eacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(155920, 1536)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------------------------------\n",
    "#               Update Model Vocabulary               \n",
    "# ----------------------------------------------------\n",
    "# Save the original tokenizations\n",
    "original_tokenization = {t: tokenizer.encode(t) for t in new_tokens}    # Necessary for the training bellow\n",
    "tokenizer.add_tokens(list(new_tokens))\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f92817b",
   "metadata": {},
   "source": [
    "3. Initialize the embeddings using the Weighted average $w_i = w_{i+1} \\times K$ with $K=5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b365d489",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing the embeddings for the new_tokens: 100%|██████████| 4255/4255 [00:00<00:00, 8683.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# Step 4. Calculate the new embeddings for the new tokens\n",
    "embed = model.get_input_embeddings().weight.clone().to('cpu')\n",
    "new_embed = model.get_input_embeddings()\n",
    "\n",
    "# Initialize the embedding using the weighted average model\n",
    "K = 1.5 # Tested for values [1, 2, 3, 4, 5, 0.9, 0.8, 1.1, 1.2, ..., 1.6] and the best was 1.5 with (3.13%)\n",
    "with torch.no_grad():\n",
    "    for new_token in tqdm.tqdm(new_tokens, desc='Initializing the embeddings for the new_tokens'):\n",
    "        new_token_id = tokenizer.encode(new_token)[0]\n",
    "        # Find the old embedding for the token\n",
    "        tokenization = original_tokenization[new_token]\n",
    "        token_embed = torch.stack([embed[t_id] for t_id in tokenization]).to(DEVICE)\n",
    "        # Calculating the embedding weights\n",
    "        embedding_weights = torch.asarray([K**i if K**i < 2**64 else 0 for i in range(token_embed.shape[0], 0, -1)]).to(DEVICE)\n",
    "        # embedding_weights = torch.asarray([K**i for i in range(token_embed.shape[0], 0, -1)]).to(DEVICE)\n",
    "        embedding_weights = embedding_weights / embedding_weights.sum()\n",
    "\n",
    "        # Create a new token embed using the weighted average of the embeddings\n",
    "        new_token_embed = torch.sum(token_embed * embedding_weights[:, None], dim=0)\n",
    "        # new_token_embed = token_embed[0]\n",
    "        # Update embedding of the new_token in the hacked_model\n",
    "        _ = new_embed.weight[new_token_id].data.copy_(new_token_embed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cc889e",
   "metadata": {},
   "source": [
    "### Benchmark Computation\n",
    "\n",
    "Calculating the results with the added tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77f11654",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<Qwen/Qwen2.5-1.5B-Instruct-ADDED_TOKENS_INIT_K=1.5> Calculating inferences for inputs: 100%|██████████| 260/260 [01:33<00:00,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`CalamePT` Accuracy for Baseline  Model `Qwen/Qwen2.5-1.5B-Instruct-ADDED_TOKENS_INIT_K=1.5` = 49.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Update model name\n",
    "model.name_or_path = f'{MODEL}-ADDED_TOKENS_INIT_K={K}'\n",
    "\n",
    "# Update the \"max_new_tokens\" (since we added new_tokens, we may have a different value than previously)\n",
    "benchmark.config['max_new_tokens'] = max(len(tokenizer.encode(x)) for x in CalamePT().df['last_word'].values) + 1   # Maximum tokenization of predicted words\n",
    "benchmark_results_new_tokens = benchmark.run(model, tokenizer, original_tokenizer, generation_kwargs=MODEL_GEN_KWARGS, store_generation_data=False)\n",
    "print(f\"`CalamePT` Accuracy for Baseline  Model `{model.name_or_path}` = {benchmark_results_new_tokens['CalamePT']['result']:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7857619",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation with new tokenizer = ` Ela correu durante horas para alcançar a linha de chegada. A corrida foi um desaf`\n",
      "Generation with \"old tokenizer\" = ` Ela correu durante horas para alcançar a linha de chegada. A corrida foi muito intensa`\n"
     ]
    }
   ],
   "source": [
    "phrase = ' Ela correu durante horas para alcançar a linha de'\n",
    "max_new_tokens = 10\n",
    "generation = tokenizer.decode(utils.generate(\n",
    "    model, tokenizer,\n",
    "    phrase,\n",
    "    DEVICE, \n",
    "    False, False,\n",
    "    max_new_tokens=max_new_tokens,\n",
    "    **MODEL_GEN_KWARGS\n",
    ")[0])\n",
    "print(f'Generation with new tokenizer = `{generation}`')\n",
    "\n",
    "\n",
    "input_ids = tokenizer.encode(phrase)\n",
    "input_ids = [token for x in input_ids for token in original_tokenization.get(tokenizer.convert_ids_to_tokens(x), [x])]\n",
    "\n",
    "for n in range(10):\n",
    "    generation = model.generate(torch.Tensor([input_ids]).long().to(DEVICE), max_new_tokens=1, **MODEL_GEN_KWARGS)\n",
    "    generated_id = generation[0, -1].item()\n",
    "    input_ids.extend(\n",
    "        [token for token in original_tokenization.get(tokenizer.convert_ids_to_tokens(generated_id), [generated_id])]\n",
    "    )\n",
    "print(f'Generation with \"old tokenizer\" = `{tokenizer.decode(input_ids)}`')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46a8dd2",
   "metadata": {},
   "source": [
    "## Model with additional Tokens + \"Training\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67017999",
   "metadata": {},
   "source": [
    "Training the model (already has the added tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac64f97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating the embeddings for the new tokens: 100%|██████████| 4255/4255 [29:28<00:00,  2.41it/s]  \n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------\n",
    "#     Update weights of Embeddings of new_tokens      \n",
    "# ----------------------------------------------------\n",
    "# Step 4.2 Using the training phrases to update the embedding weights\n",
    "learning_rate = 1e-6\n",
    "training_phrases: list[str] = CalamePT().prediction_prompts.to_list() # CalamePT dataset \n",
    "for new_token in tqdm.tqdm(new_tokens, desc='Updating the embeddings for the new tokens'):\n",
    "    new_token_id = tokenizer.convert_tokens_to_ids(new_token)\n",
    "    new_token = tokenizer.decode(new_token_id)\n",
    "    phrases_to_generate_new_token = [p for phrase in training_phrases for p in phrase.split(new_token)[:-1] if new_token in phrase and len(p) > 0]\n",
    "\n",
    "    if len(phrases_to_generate_new_token) == 0: continue\n",
    "    # Creating the Batched dataset (to run generation for multiple phrases at the same time)\n",
    "    dataloader = DataLoader(\n",
    "        TextDataset(phrases_to_generate_new_token, tokenizer, max_length=max(len(tokenizer.tokenize(x)) for x in phrases_to_generate_new_token)),\n",
    "        batch_size=GENERATION_BATCH_SIZE,\n",
    "        shuffle=False\n",
    "    )\n",
    "    # Process the batches\n",
    "    for batch in tqdm.tqdm(dataloader,  desc=f'  Generating tokens for new_token=`{new_token}` ', leave=False):\n",
    "        # Move batch tensors to the correct device\n",
    "        input_ids = batch['input_ids'].squeeze(1).to(DEVICE)\n",
    "        attention_mask = batch['attention_mask'].squeeze(1).to(DEVICE)\n",
    "\n",
    "        # Generate text\n",
    "        outputs = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=1,\n",
    "            num_beams=1,\n",
    "            num_return_sequences=1,\n",
    "            return_dict_in_generate=True,\n",
    "            output_logits=True,\n",
    "            output_scores=True,\n",
    "            output_hidden_states=True,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            **MODEL_GEN_KWARGS\n",
    "        )\n",
    "\n",
    "        # Extract the generated sequences and their scores\n",
    "        generated_sequences = outputs.sequences\n",
    "        predicted_logits = outputs.logits\n",
    "\n",
    "        # Decode the input and generated sequences\n",
    "        input_texts = tokenizer.batch_decode(input_ids, skip_special_tokens=True)\n",
    "        generated_texts = tokenizer.batch_decode(generated_sequences, skip_special_tokens=True)\n",
    "        with torch.no_grad():\n",
    "            for i in range(len(input_texts)):\n",
    "                logits = predicted_logits[0][i]\n",
    "                logit_gradient = logits.max() - logits[new_token_id]\n",
    "                embed_out = outputs.hidden_states[0][-1][i][-1]\n",
    "                # normalize embed_out\n",
    "                embed_out = embed_out / embed_out.norm()\n",
    "\n",
    "                embed_in = new_embed.weight[new_token_id]\n",
    "\n",
    "                # Update the embedding table\n",
    "                _ = new_embed.weight[new_token_id].data.copy_((embed_in + logit_gradient * embed_out * learning_rate).to(DEVICE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecc32e0",
   "metadata": {},
   "source": [
    "### Update model name\n",
    "\n",
    "Changing the model name to include the \"added_tokens\" to distinguish between the older model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "409a35f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.name_or_path = f'{model.name_or_path} [TRAINED]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df0d075",
   "metadata": {},
   "source": [
    "### Run the benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6cc5799",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<Qwen/Qwen2.5-1.5B-Instruct-ADDED_TOKENS_INIT_K=1.5 [TRAINED]> Calculating inferences for inputs: 100%|██████████| 260/260 [01:37<00:00,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`CalamePT` Accuracy for Baseline Model `Qwen/Qwen2.5-1.5B-Instruct-ADDED_TOKENS_INIT_K=1.5 [TRAINED]` = 49.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "benchmark_results_new_tokens_trained = benchmark.run(model, tokenizer, original_tokenizer,  generation_kwargs=MODEL_GEN_KWARGS)\n",
    "print(f\"`CalamePT` Accuracy for Baseline Model `{model.name_or_path}` = {benchmark_results_new_tokens_trained['CalamePT']['result']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12688c69",
   "metadata": {},
   "source": [
    "## Checking the Ranks of new_tokens matching \"correct Word\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c907f07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_tokenizer_size = len(original_tokenizer)\n",
    "for gen in benchmark_results_new_tokens_trained['CalamePT']['results'][0]['benchmark_predictions']:\n",
    "    if 'logits_new_token' in gen:\n",
    "        gen.pop('logits_new_token')\n",
    "        gen.pop('rank_new_token')\n",
    "    correct_word = gen['correct_word']\n",
    "    tokenization_correct_word = tokenizer.encode(correct_word)\n",
    "    if len(tokenization_correct_word) > 1:\n",
    "        tokenization_correct_word = tokenizer.encode(' ' + correct_word)\n",
    "    if len(tokenization_correct_word) > 1:\n",
    "        continue\n",
    "    if tokenization_correct_word[0] < original_tokenizer_size:\n",
    "        continue\n",
    "    gen['logits_new_token'] = gen['generated_logits'][0][tokenization_correct_word[0]]\n",
    "    gen['rank_new_token'] = (gen['generated_logits'][0] > gen['logits_new_token']).sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f158c9",
   "metadata": {},
   "source": [
    "## Saving results as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "69fff788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prediction",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "correct_word",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "logits_new_token",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "rank_new_token",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "new_token_id",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "new_token",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "a38e79f1-0c3b-4b17-b6cc-4ad0af7c27c9",
       "rows": [
        [
         "0",
         " Ela correu durante horas para alcançar a linha de",
         "chegada",
         "chegada",
         "tensor(12.3750)",
         "38.0",
         "154849.0",
         "` chegada`"
        ],
        [
         "1",
         "Ela cantou tão bem no concerto que emocionou o",
         "público",
         "público",
         null,
         null,
         null,
         null
        ],
        [
         "2",
         "Os ventos fortes causaram com que algumas árvores",
         "caíssem",
         "caíssem",
         null,
         null,
         null,
         null
        ],
        [
         "3",
         "O Jorge trabalhava numa padaria. Todos os dias ele vendia",
         "100000",
         "pão",
         "tensor(5.5625)",
         "4617.0",
         null,
         null
        ],
        [
         "4",
         "As equipas de futebol têm vários jogadores, e todos têm que respeitar o seu",
         "lugar",
         "treinador",
         "tensor(8.)",
         "1851.0",
         null,
         null
        ],
        [
         "5",
         "Os pássaros voaram alto no",
         "céu",
         "céu",
         "tensor(11.3750)",
         "142.0",
         "152437.0",
         "` céu`"
        ],
        [
         "6",
         "O sol brilhou intensamente durante o",
         "dia",
         "dia",
         null,
         null,
         null,
         null
        ],
        [
         "7",
         "A chuva caiu suavemente sobre as folhas das",
         "árvores",
         "árvores",
         "tensor(10.)",
         "423.0",
         "153289.0",
         "` árvores`"
        ],
        [
         "8",
         "A comida estava deliciosa e deixou todos",
         "felizes",
         "satisfeitos",
         null,
         null,
         null,
         null
        ],
        [
         "9",
         "Era noite de Natal, e a criança sorriu ao receber o",
         "presente",
         "presente",
         null,
         null,
         null,
         null
        ],
        [
         "10",
         "A montanha era tão alta que parecia tocar o",
         "céu",
         "céu",
         "tensor(15.9375)",
         "1.0",
         "152437.0",
         "` céu`"
        ],
        [
         "11",
         "O jardim estava repleto de flores coloridas. Os pássaros cantavam alegremente nas árvores. O sol brilhava intensamente no céu",
         "azul",
         "azul",
         "tensor(11.9375)",
         "97.0",
         "155462.0",
         "` azul`"
        ],
        [
         "12",
         "O filme era emocionante do início ao fim. Os atores interpretaram os seus papéis com maestria. O público aplaudiu de pé no final da",
         "sessão",
         "sessão",
         null,
         null,
         null,
         null
        ],
        [
         "13",
         "O mar estava agitado e as ondas arrebentavam com força na praia. As crianças construíam castelos de areia. Os surfistas aproveitavam as ",
         "10h",
         "ondas",
         "tensor(7.1562)",
         "2056.0",
         null,
         null
        ],
        [
         "14",
         "O livro tinha uma capa intrigante. A história cativou desde o primeiro capítulo. O final deixou um mistério no",
         "ar",
         "ar",
         null,
         null,
         null,
         null
        ],
        [
         "15",
         "O concerto começou com uma música suave. O público estava em silêncio, absorvendo a música. O clímax da apresentação foi arrebatador, deixando todos de pé a",
         "aplaudir",
         "aplaudir",
         null,
         null,
         null,
         null
        ],
        [
         "16",
         "A manhã começou com um céu claro e ensolarado. O café estava quente e perfumado. As pessoas saíram de casa com sorrisos no ",
         "rosto",
         "rosto",
         null,
         null,
         null,
         null
        ],
        [
         "17",
         "O parque estava cheio de crianças a brincar. Os pássaros voavam de árvore em árvore. Os adultos relaxavam nos bancos, a aproveitar o",
         "sol",
         "dia",
         null,
         null,
         null,
         null
        ],
        [
         "18",
         "O trilho na montanha era desafiadora. A vista do topo era espetacular. O grupo comemorou o sucesso da ",
         "1ª",
         "escalada",
         null,
         null,
         null,
         null
        ],
        [
         "19",
         "A chuva caiu suavemente durante a noite. As gotas batiam na janela. O som relaxante embalou o sono",
         "da",
         "profundo",
         "tensor(9.5625)",
         "779.0",
         null,
         null
        ],
        [
         "20",
         "O cientista fez uma descoberta revolucionária. A comunidade científica ficou impressionada com os resultados. Foi um belo contributo para a sua",
         "área",
         "área",
         null,
         null,
         null,
         null
        ],
        [
         "21",
         "O restaurante tinha um menu variado. Os empregados eram atenciosos e prestativos. A sobremesa era a melhor parte da ",
         "experiência",
         "refeição",
         null,
         null,
         null,
         null
        ],
        [
         "22",
         "O livro de receitas tinha pratos exóticos. A cozinheira seguiu as instruções à risca. O resultado foi um jantar que parecia ter sido cozinhado por um",
         "chef",
         "chef",
         null,
         null,
         null,
         null
        ],
        [
         "23",
         "O teatro estava lotado para a peça de abertura. O cenário e os figurinos eram deslumbrantes. Os atores receberam uma ovação de pé no final do",
         "espetáculo",
         "espétaculo",
         null,
         null,
         "152580.0",
         "` espetáculo`"
        ],
        [
         "24",
         "A cidade acordou com neve a cobrir as ruas. As crianças saíram para fazer bonecos de neve. Os adultos reuniram-se em frente à lareira para se",
         "aquecerem",
         "aquecer",
         null,
         null,
         null,
         null
        ],
        [
         "25",
         "Devido aos ventos fortes e ao calor abrasador, os bombeiros tiveram muita dificuldade em combater o",
         "incêndio",
         "fogo",
         "tensor(12.6875)",
         "20.0",
         null,
         null
        ],
        [
         "26",
         "O mercado estava cheio de cores e aromas. As barracas vendiam frutas frescas e legumes. As pessoas conversavam animadamente enquanto faziam as suas ",
         "compras",
         "compras",
         null,
         null,
         null,
         null
        ],
        [
         "27",
         "O parque nacional era um paraíso para os amantes da natureza. Os trilhos levavam a cascatas escondidas. Os animais selvagens podiam ser vistos no seu habitat",
         "natural",
         "natural",
         null,
         null,
         null,
         null
        ],
        [
         "28",
         "A viagem de comboio atravessou paisagens pitorescas. Os passageiros tiraram fotos das montanhas e vales. O pôr do sol no horizonte era de tirar o",
         "fôlego",
         "fôlego",
         null,
         null,
         null,
         null
        ],
        [
         "29",
         "O novo dispositivo eletrônico tinha recursos impressionantes. Os consumidores estavam ansiosos para experimentá-lo. O lançamento foi um grande ",
         "ousado",
         "sucesso",
         null,
         null,
         null,
         null
        ],
        [
         "30",
         "A festa de aniversário tinha decorações temáticas incríveis. Os convidados participaram em jogos divertidos. No fim, todos comeram o",
         "bolo",
         "bolo",
         "tensor(14.)",
         "27.0",
         "155795.0",
         "` bolo`"
        ],
        [
         "31",
         "A corrida de carros foi emocionante do início ao fim. Os pilotos competiram em alta velocidade. O vencedor comemorou no pódio com uma garrafa de ",
         "750ml",
         "champanhe",
         null,
         null,
         null,
         null
        ],
        [
         "32",
         "O acampamento no deserto ofereceu vistas espetaculares do céu noturno. As fogueiras aqueceram as noites frias. Os sons da natureza embalaram os acampantes para o",
         "dia",
         "sono",
         null,
         null,
         null,
         null
        ],
        [
         "33",
         "O piquenique no parque reuniu amigos e familiares. A comida caseira era deliciosa. As crianças brincaram alegremente sob o",
         "sol",
         "sol",
         null,
         null,
         null,
         null
        ],
        [
         "34",
         "A reunião de negócios foi produtiva e eficiente. As ideias foram discutidas de maneira construtiva. O acordo foi alcançado no final da",
         "reunião",
         "reunião",
         "tensor(10.8125)",
         "123.0",
         "152199.0",
         "` reunião`"
        ],
        [
         "35",
         "O festival de música trouxe bandas famosas para o palco principal. Os fãs dançaram e cantaram ao longo do evento. Todos gostaram dos",
         "shows",
         "concertos",
         null,
         null,
         null,
         null
        ],
        [
         "36",
         "O concerto ao ar livre atraiu uma multidão entusiasmada. As bandas locais mostraram seu talento musical. A música ecoou sob as ",
         "10000000",
         "estrelas",
         "tensor(6.4375)",
         "4000.0",
         null,
         null
        ],
        [
         "37",
         "As rendas dos imóveis estão demasiado elevadas. Infelizmente, os jovens não conseguem arrendar porque os seus salários não acompanharam este",
         "aumento",
         "aumento",
         null,
         null,
         null,
         null
        ],
        [
         "38",
         "A estação de comboios tinha muita gente, e ele já estava atrasado. Felizmente, ele conseguiu apanhar o seu comboio porque este também se",
         "encontrava",
         "atrasou",
         null,
         null,
         null,
         null
        ],
        [
         "39",
         "A estação espacial anda em órbita do nosso",
         "planeta",
         "planeta",
         null,
         null,
         null,
         null
        ],
        [
         "40",
         "O carro já não era utilizado há vários meses. Quando ele o tentou ligar, não conseguiu. O mais provável é a bateria ter ficado sem",
         "energia",
         "energia",
         null,
         null,
         null,
         null
        ],
        [
         "41",
         "O jogo de futebol foi emocionante do início ao fim. Os torcedores vibraram nas arquibancadas. O gol no último minuto selou a vitória da",
         "equipe",
         "equipa",
         "tensor(9.1250)",
         "321.0",
         null,
         null
        ],
        [
         "42",
         "O acampamento de verão ofereceu atividades ao ar livre emocionantes. As crianças fizeram amizades duradouras. As noites foram memoráveis ao redor da",
         "lareira",
         "fogueira ",
         null,
         null,
         null,
         null
        ],
        [
         "43",
         "A exposição de fotografia exibiu imagens incríveis. Os fotógrafos capturaram momentos únicos. Os visitantes se sentiram inspirados pela beleza das",
         "fotos",
         "fotografias",
         null,
         null,
         null,
         null
        ],
        [
         "44",
         "O passeio de bicicleta pela zona rural foi revigorante. As estradas sinuosas levaram a vistas panorâmicas. O ar fresco rejuvenesceu os",
         "pulmões",
         "ciclistas",
         null,
         null,
         null,
         null
        ],
        [
         "45",
         "O documentário explorou questões sociais importantes. Os entrevistados partilharam suas experiências e perspectivas. O filme provocou discussões sobre justiça e",
         "igualdade",
         "igualdade",
         null,
         null,
         null,
         null
        ],
        [
         "46",
         "A livraria independente tinha uma seleção eclética de livros. Os leitores exploravam os corredores em busca de tesouros literários. A atmosfera aconchegante convidava à ",
         "erva",
         "leitura",
         null,
         null,
         null,
         null
        ],
        [
         "47",
         "O acampamento noturno sob as estrelas proporcionou uma experiência mágica. Os participantes contemplavam o céu estrelado. As histórias em torno da fogueira uniam o",
         "grupo",
         "grupo",
         null,
         null,
         null,
         null
        ],
        [
         "48",
         "O passeio de barco pelo rio revelou paisagens pitorescas. A água calma refletia as montanhas à distância. A tranquilidade da natureza envolveu todos os que estavam a",
         "bordo",
         "bordo",
         "tensor(13.7500)",
         "19.0",
         "155552.0",
         "` bordo`"
        ],
        [
         "49",
         "O laboratório de pesquisa estava focado em inovações tecnológicas. Os cientistas trabalhavam incansavelmente em experiências avançadas. As descobertas prometiam transformar o",
         "mundo",
         "futuro",
         null,
         null,
         null,
         null
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 2076
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>prediction</th>\n",
       "      <th>correct_word</th>\n",
       "      <th>logits_new_token</th>\n",
       "      <th>rank_new_token</th>\n",
       "      <th>new_token_id</th>\n",
       "      <th>new_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ela correu durante horas para alcançar a linh...</td>\n",
       "      <td>chegada</td>\n",
       "      <td>chegada</td>\n",
       "      <td>tensor(12.3750)</td>\n",
       "      <td>38.0</td>\n",
       "      <td>154849.0</td>\n",
       "      <td>` chegada`</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ela cantou tão bem no concerto que emocionou o</td>\n",
       "      <td>público</td>\n",
       "      <td>público</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Os ventos fortes causaram com que algumas árvores</td>\n",
       "      <td>caíssem</td>\n",
       "      <td>caíssem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O Jorge trabalhava numa padaria. Todos os dias...</td>\n",
       "      <td>100000</td>\n",
       "      <td>pão</td>\n",
       "      <td>tensor(5.5625)</td>\n",
       "      <td>4617.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As equipas de futebol têm vários jogadores, e ...</td>\n",
       "      <td>lugar</td>\n",
       "      <td>treinador</td>\n",
       "      <td>tensor(8.)</td>\n",
       "      <td>1851.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071</th>\n",
       "      <td>A requalificação dos espaços verdes é uma prio...</td>\n",
       "      <td>verdes</td>\n",
       "      <td>verdes</td>\n",
       "      <td>tensor(15.6250)</td>\n",
       "      <td>14.0</td>\n",
       "      <td>155141.0</td>\n",
       "      <td>` verdes`</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>Os adeptos de hóquei em patins podem esperar u...</td>\n",
       "      <td>equipes</td>\n",
       "      <td>equipas</td>\n",
       "      <td>tensor(14.1875)</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>Uma estrela brilhante se junta às demais no fa...</td>\n",
       "      <td>artista</td>\n",
       "      <td>atriz</td>\n",
       "      <td>tensor(10.3750)</td>\n",
       "      <td>340.0</td>\n",
       "      <td>153499.0</td>\n",
       "      <td>` artista`</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2074</th>\n",
       "      <td>Uma nova exposição de arte contemporânea explo...</td>\n",
       "      <td>género</td>\n",
       "      <td>género</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>No contexto apresentado, várias organizações d...</td>\n",
       "      <td>empregados</td>\n",
       "      <td>trabalhadores</td>\n",
       "      <td>tensor(13.5625)</td>\n",
       "      <td>24.0</td>\n",
       "      <td>153552.0</td>\n",
       "      <td>` empregados`</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2076 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  prediction  \\\n",
       "0      Ela correu durante horas para alcançar a linh...     chegada   \n",
       "1        Ela cantou tão bem no concerto que emocionou o     público   \n",
       "2     Os ventos fortes causaram com que algumas árvores     caíssem   \n",
       "3     O Jorge trabalhava numa padaria. Todos os dias...      100000   \n",
       "4     As equipas de futebol têm vários jogadores, e ...       lugar   \n",
       "...                                                 ...         ...   \n",
       "2071  A requalificação dos espaços verdes é uma prio...      verdes   \n",
       "2072  Os adeptos de hóquei em patins podem esperar u...     equipes   \n",
       "2073  Uma estrela brilhante se junta às demais no fa...     artista   \n",
       "2074  Uma nova exposição de arte contemporânea explo...      género   \n",
       "2075  No contexto apresentado, várias organizações d...  empregados   \n",
       "\n",
       "       correct_word logits_new_token  rank_new_token  new_token_id  \\\n",
       "0           chegada  tensor(12.3750)            38.0      154849.0   \n",
       "1           público              NaN             NaN           NaN   \n",
       "2           caíssem              NaN             NaN           NaN   \n",
       "3               pão   tensor(5.5625)          4617.0           NaN   \n",
       "4         treinador       tensor(8.)          1851.0           NaN   \n",
       "...             ...              ...             ...           ...   \n",
       "2071         verdes  tensor(15.6250)            14.0      155141.0   \n",
       "2072        equipas  tensor(14.1875)             8.0           NaN   \n",
       "2073          atriz  tensor(10.3750)           340.0      153499.0   \n",
       "2074         género              NaN             NaN           NaN   \n",
       "2075  trabalhadores  tensor(13.5625)            24.0      153552.0   \n",
       "\n",
       "          new_token  \n",
       "0        ` chegada`  \n",
       "1              None  \n",
       "2              None  \n",
       "3              None  \n",
       "4              None  \n",
       "...             ...  \n",
       "2071      ` verdes`  \n",
       "2072           None  \n",
       "2073     ` artista`  \n",
       "2074           None  \n",
       "2075  ` empregados`  \n",
       "\n",
       "[2076 rows x 7 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_without_tensors = [\n",
    "    {k: v for k, v in data.items() if not k in ['generated_ids', 'generated_logits']}\n",
    "    for data in benchmark_results_new_tokens_trained['CalamePT']['results'][0]['benchmark_predictions']\n",
    "]\n",
    "df = pd.DataFrame(data_without_tensors)\n",
    "\n",
    "# Add the \"token_id\" and \"new_token\" to dataframe\n",
    "def get_predicted_word_token(row: pd.Series):\n",
    "    if row['rank_new_token'] is None: return None\n",
    "    output = tokenizer.convert_tokens_to_ids(row['prediction'])\n",
    "    if output is None or output < original_tokenizer_size:\n",
    "        output = tokenizer.convert_tokens_to_ids(' ' + row['prediction'])\n",
    "    return output\n",
    "df['new_token_id'] = df.apply(get_predicted_word_token, axis=1)\n",
    "df['new_token'] = df['new_token_id'].apply(lambda x: f'`{tokenizer.decode([int(x)])}`' if x is not None and not pd.isna(x) else None) \n",
    "\n",
    "df.to_csv('CALAMEPT_new_token_trained_ranks.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5197888",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_with_new_token = df[df['rank_new_token'] == 1]['text'].to_list()\n",
    "tmp = [k for k in benchmark_results_new_tokens_trained['CalamePT']['results'][0]['benchmark_predictions'] if k['text'] in texts_with_new_token]\n",
    "tmp[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcdc97e",
   "metadata": {},
   "source": [
    "## Checking which \"new_Tokens\" were generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd79133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding out which \"new_tokens\" were generated\n",
    "tmp = [x['generated_ids'].max().item() for x in benchmark_results_new_tokens_trained['CalamePT']['results'][0]['benchmark_predictions']]\n",
    "# len([t for t in tmp if t>len(original_tokenizer)])\n",
    "\n",
    "# Adding flag of \"new_token_generated\" in benchmark results\n",
    "original_tokenizer_size = len(original_tokenizer)\n",
    "for i, test in tqdm.tqdm(enumerate(benchmark_results_new_tokens_trained['CalamePT']['results'][0]['benchmark_predictions'])):\n",
    "    test['has_new_token'] = len([t for t in test['generated_ids'] if t>original_tokenizer_size]) > 0\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0c4060",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_w_new_tokens = [a.copy() for a in benchmark_results_new_tokens_trained['CalamePT']['results'][0]['benchmark_predictions'] if a['has_new_token']]\n",
    "def word_has_new_token(word: str, token_ids, new_token_start_id: int):\n",
    "    i = 1\n",
    "    cur_tokens = [token_ids[0]]\n",
    "    while tokenizer.decode(cur_tokens).strip().lower() != word.lower() and i<len(token_ids):\n",
    "        cur_tokens.append(token_ids[i])\n",
    "        i+=1\n",
    "    return len([t for t in cur_tokens if new_token_start_id < t]) > 0\n",
    "\n",
    "new_token_start_id = len(original_tokenizer)\n",
    "for i, r in enumerate(results_w_new_tokens):\n",
    "    # Find out if \"predicted_word\" is made up of any \"new_token\"\n",
    "    results_w_new_tokens[i]['new_token_in_word'] = word_has_new_token(r['prediction'], r['generated_ids'][-8:], new_token_start_id)\n",
    "    results_w_new_tokens[i]['correct_prediction'] = r['prediction'].strip().lower() == r['correct_word'].strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78763c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "[r for r in results_w_new_tokens if r['new_token_in_word'] and r['correct_prediction']]\n",
    "# results_w_new_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d79d58",
   "metadata": {},
   "source": [
    "SAVE ALL Benchmarks in a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f4e1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import gzip\n",
    "\n",
    "class TensorJSONEncoder(json.JSONEncoder):\n",
    "    \"\"\"Custom JSON Encoder that handles PyTorch Tensors, NumPy arrays, and other non-serializable objects.\"\"\"\n",
    "    \n",
    "    def default(self, obj):\n",
    "        # PyTorch Tensors → Python list\n",
    "        if isinstance(obj, torch.Tensor):\n",
    "            return obj.cpu().tolist()  # Move to CPU and convert to list\n",
    "        \n",
    "        # NumPy arrays → Python list\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        \n",
    "        # Handle other non-serializable objects (e.g., datetime)\n",
    "        try:\n",
    "            return super().default(obj)\n",
    "        except TypeError:\n",
    "            return str(obj)  # Fallback to string representation\n",
    "\n",
    "with gzip.open('/home/yali/MEGA/Hack The Tockenizer/tests/qwen2.5-benchmark-results_V2_run_final_version.json.gz', 'wt') as f:\n",
    "    json.dump(benchmark.get_results(), f, indent=2, ensure_ascii=False, cls=TensorJSONEncoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
